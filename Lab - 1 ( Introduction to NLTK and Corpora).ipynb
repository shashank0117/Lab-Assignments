{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "brown.categories()\n",
    "brown.words(categories = 'adventure')\n",
    "brown.words(categories = 'hobbies')\n",
    "brown.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['Fellow', '-', 'Citizens', 'of', 'the', 'Senate', 'and', 'of', 'the', 'House', 'of', 'Representatives', ':']], [['Among', 'the', 'vicissitudes', 'incident', 'to', 'life', 'no', 'event', 'could', 'have', 'filled', 'me', 'with', 'greater', 'anxieties', 'than', 'that', 'of', 'which', 'the', 'notification', 'was', 'transmitted', 'by', 'your', 'order', ',', 'and', 'received', 'on', 'the', '14th', 'day', 'of', 'the', 'present', 'month', '.'], ['On', 'the', 'one', 'hand', ',', 'I', 'was', 'summoned', 'by', 'my', 'Country', ',', 'whose', 'voice', 'I', 'can', 'never', 'hear', 'but', 'with', 'veneration', 'and', 'love', ',', 'from', 'a', 'retreat', 'which', 'I', 'had', 'chosen', 'with', 'the', 'fondest', 'predilection', ',', 'and', ',', 'in', 'my', 'flattering', 'hopes', ',', 'with', 'an', 'immutable', 'decision', ',', 'as', 'the', 'asylum', 'of', 'my', 'declining', 'years', '--', 'a', 'retreat', 'which', 'was', 'rendered', 'every', 'day', 'more', 'necessary', 'as', 'well', 'as', 'more', 'dear', 'to', 'me', 'by', 'the', 'addition', 'of', 'habit', 'to', 'inclination', ',', 'and', 'of', 'frequent', 'interruptions', 'in', 'my', 'health', 'to', 'the', 'gradual', 'waste', 'committed', 'on', 'it', 'by', 'time', '.'], ['On', 'the', 'other', 'hand', ',', 'the', 'magnitude', 'and', 'difficulty', 'of', 'the', 'trust', 'to', 'which', 'the', 'voice', 'of', 'my', 'country', 'called', 'me', ',', 'being', 'sufficient', 'to', 'awaken', 'in', 'the', 'wisest', 'and', 'most', 'experienced', 'of', 'her', 'citizens', 'a', 'distrustful', 'scrutiny', 'into', 'his', 'qualifications', ',', 'could', 'not', 'but', 'overwhelm', 'with', 'despondence', 'one', 'who', '(', 'inheriting', 'inferior', 'endowments', 'from', 'nature', 'and', 'unpracticed', 'in', 'the', 'duties', 'of', 'civil', 'administration', ')', 'ought', 'to', 'be', 'peculiarly', 'conscious', 'of', 'his', 'own', 'deficiencies', '.'], ['In', 'this', 'conflict', 'of', 'emotions', 'all', 'I', 'dare', 'aver', 'is', 'that', 'it', 'has', 'been', 'my', 'faithful', 'study', 'to', 'collect', 'my', 'duty', 'from', 'a', 'just', 'appreciation', 'of', 'every', 'circumstance', 'by', 'which', 'it', 'might', 'be', 'affected', '.'], ['All', 'I', 'dare', 'hope', 'is', 'that', 'if', ',', 'in', 'executing', 'this', 'task', ',', 'I', 'have', 'been', 'too', 'much', 'swayed', 'by', 'a', 'grateful', 'remembrance', 'of', 'former', 'instances', ',', 'or', 'by', 'an', 'affectionate', 'sensibility', 'to', 'this', 'transcendent', 'proof', 'of', 'the', 'confidence', 'of', 'my', 'fellow', 'citizens', ',', 'and', 'have', 'thence', 'too', 'little', 'consulted', 'my', 'incapacity', 'as', 'well', 'as', 'disinclination', 'for', 'the', 'weighty', 'and', 'untried', 'cares', 'before', 'me', ',', 'my', 'error', 'will', 'be', 'palliated', 'by', 'the', 'motives', 'which', 'mislead', 'me', ',', 'and', 'its', 'consequences', 'be', 'judged', 'by', 'my', 'country', 'with', 'some', 'share', 'of', 'the', 'partiality', 'in', 'which', 'they', 'originated', '.']], ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import inaugural\n",
    "inaugural.fileids()\n",
    "inaugural.words('1789-Washington.txt')\n",
    "inaugural.sents('1789-Washington.txt')\n",
    "inaugural.paras('1789-Washington.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['och',\n",
       " 'det',\n",
       " 'att',\n",
       " 'i',\n",
       " 'en',\n",
       " 'jag',\n",
       " 'hon',\n",
       " 'som',\n",
       " 'han',\n",
       " 'på',\n",
       " 'den',\n",
       " 'med',\n",
       " 'var',\n",
       " 'sig',\n",
       " 'för',\n",
       " 'så',\n",
       " 'till',\n",
       " 'är',\n",
       " 'men',\n",
       " 'ett',\n",
       " 'om',\n",
       " 'hade',\n",
       " 'de',\n",
       " 'av',\n",
       " 'icke',\n",
       " 'mig',\n",
       " 'du',\n",
       " 'henne',\n",
       " 'då',\n",
       " 'sin',\n",
       " 'nu',\n",
       " 'har',\n",
       " 'inte',\n",
       " 'hans',\n",
       " 'honom',\n",
       " 'skulle',\n",
       " 'hennes',\n",
       " 'där',\n",
       " 'min',\n",
       " 'man',\n",
       " 'ej',\n",
       " 'vid',\n",
       " 'kunde',\n",
       " 'något',\n",
       " 'från',\n",
       " 'ut',\n",
       " 'när',\n",
       " 'efter',\n",
       " 'upp',\n",
       " 'vi',\n",
       " 'dem',\n",
       " 'vara',\n",
       " 'vad',\n",
       " 'över',\n",
       " 'än',\n",
       " 'dig',\n",
       " 'kan',\n",
       " 'sina',\n",
       " 'här',\n",
       " 'ha',\n",
       " 'mot',\n",
       " 'alla',\n",
       " 'under',\n",
       " 'någon',\n",
       " 'eller',\n",
       " 'allt',\n",
       " 'mycket',\n",
       " 'sedan',\n",
       " 'ju',\n",
       " 'denna',\n",
       " 'själv',\n",
       " 'detta',\n",
       " 'åt',\n",
       " 'utan',\n",
       " 'varit',\n",
       " 'hur',\n",
       " 'ingen',\n",
       " 'mitt',\n",
       " 'ni',\n",
       " 'bli',\n",
       " 'blev',\n",
       " 'oss',\n",
       " 'din',\n",
       " 'dessa',\n",
       " 'några',\n",
       " 'deras',\n",
       " 'blir',\n",
       " 'mina',\n",
       " 'samma',\n",
       " 'vilken',\n",
       " 'er',\n",
       " 'sådan',\n",
       " 'vår',\n",
       " 'blivit',\n",
       " 'dess',\n",
       " 'inom',\n",
       " 'mellan',\n",
       " 'sådant',\n",
       " 'varför',\n",
       " 'varje',\n",
       " 'vilka',\n",
       " 'ditt',\n",
       " 'vem',\n",
       " 'vilket',\n",
       " 'sitta',\n",
       " 'sådana',\n",
       " 'vart',\n",
       " 'dina',\n",
       " 'vars',\n",
       " 'vårt',\n",
       " 'våra',\n",
       " 'ert',\n",
       " 'era',\n",
       " 'vilkas']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words(\"russian\")\n",
    "stopwords.words(\"english\")\n",
    "stopwords.words(\"swedish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE London/NNP)\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  capital/NN\n",
      "  and/CC\n",
      "  most/RBS\n",
      "  populous/JJ\n",
      "  city/NN\n",
      "  of/IN\n",
      "  (GPE England/NNP)\n",
      "  and/CC\n",
      "  the/DT\n",
      "  (ORGANIZATION United/NNP Kingdom/NNP)\n",
      "  ./.)\n",
      "(S\n",
      "  Standing/VBG\n",
      "  on/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION River/NNP Thames/NNP)\n",
      "  in/IN\n",
      "  the/DT\n",
      "  south/JJ\n",
      "  east/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  island/NN\n",
      "  of/IN\n",
      "  (GPE Great/NNP Britain/NNP)\n",
      "  ,/,\n",
      "  (GPE London/NNP)\n",
      "  has/VBZ\n",
      "  been/VBN\n",
      "  a/DT\n",
      "  major/JJ\n",
      "  settlement/NN\n",
      "  for/IN\n",
      "  two/CD\n",
      "  millennia/NN\n",
      "  ./.)\n",
      "(S\n",
      "  It/PRP\n",
      "  was/VBD\n",
      "  founded/VBN\n",
      "  by/IN\n",
      "  the/DT\n",
      "  (GPE Romans/NNPS)\n",
      "  ,/,\n",
      "  who/WP\n",
      "  named/VBD\n",
      "  it/PRP\n",
      "  Londinium/NNP\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"\"\"\n",
    "    London is the capital and most populous city of England and the United Kingdom. \n",
    "    Standing on the River Thames in the south east of the island of Great Britain, \n",
    "    London has been a major settlement for two millennia. \n",
    "    It was founded by the Romans, who named it Londinium.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words = nltk.pos_tag(words)\n",
    "        ne_tagged_words = nltk.ne_chunk(tagged_words)\n",
    "        print(ne_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133737"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries = nltk.corpus.cmudict.entries()\n",
    "len(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('belford', ['B', 'EH1', 'L', 'F', 'ER0', 'D'])\n",
      "('belfry', ['B', 'EH1', 'L', 'F', 'R', 'IY0'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'G', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgacom', ['B', 'EH1', 'L', 'JH', 'AH0', 'K', 'AA0', 'M'])\n",
      "('belgard', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D'])\n",
      "('belgarde', ['B', 'EH0', 'L', 'G', 'AA1', 'R', 'D', 'IY0'])\n",
      "('belge', ['B', 'EH1', 'L', 'JH', 'IY0'])\n",
      "('belger', ['B', 'EH1', 'L', 'G', 'ER0'])\n",
      "('belgian', ['B', 'EH1', 'L', 'JH', 'AH0', 'N'])\n",
      "('belgians', ['B', 'EH1', 'L', 'JH', 'AH0', 'N', 'Z'])\n",
      "('belgique', ['B', 'EH0', 'L', 'ZH', 'IY1', 'K'])\n",
      "(\"belgique's\", ['B', 'EH0', 'L', 'JH', 'IY1', 'K', 'S'])\n",
      "('belgium', ['B', 'EH1', 'L', 'JH', 'AH0', 'M'])\n",
      "(\"belgium's\", ['B', 'EH1', 'L', 'JH', 'AH0', 'M', 'Z'])\n",
      "('belgo', ['B', 'EH1', 'L', 'G', 'OW2'])\n",
      "('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D'])\n",
      "('belgrade', ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D'])\n",
      "(\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'EY0', 'D', 'Z'])\n",
      "(\"belgrade's\", ['B', 'EH1', 'L', 'G', 'R', 'AA2', 'D', 'Z'])\n",
      "('belgrave', ['B', 'EH1', 'L', 'G', 'R', 'EY2', 'V'])\n",
      "('beli', ['B', 'EH1', 'L', 'IY0'])\n",
      "('belich', ['B', 'EH1', 'L', 'IH0', 'K'])\n",
      "('belie', ['B', 'IH0', 'L', 'AY1'])\n",
      "('belied', ['B', 'IH0', 'L', 'AY1', 'D'])\n",
      "('belief', ['B', 'IH0', 'L', 'IY1', 'F'])\n"
     ]
    }
   ],
   "source": [
    "for entry in entries[10000:10025]:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('car.n.01')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets(\"motorcar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['car', 'auto', 'automobile', 'machine', 'motorcar']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('car.n.01').lemma_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Party', 'was', 'soooo', 'fun', ':D', '#superfun']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "text = 'The Party was soooo fun :D #superfun'\n",
    "twtkn = TweetTokenizer()\n",
    "twtkn.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Lemma.name of Lemma('stack.n.01.stack')> 2\n",
      "<bound method Lemma.name of Lemma('batch.n.02.batch')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.deal')> 1\n",
      "<bound method Lemma.name of Lemma('batch.n.02.flock')> 1\n",
      "<bound method Lemma.name of Lemma('batch.n.02.good_deal')> 13\n",
      "<bound method Lemma.name of Lemma('batch.n.02.great_deal')> 10\n",
      "<bound method Lemma.name of Lemma('batch.n.02.hatful')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.heap')> 2\n",
      "<bound method Lemma.name of Lemma('batch.n.02.lot')> 13\n",
      "<bound method Lemma.name of Lemma('batch.n.02.mass')> 14\n",
      "<bound method Lemma.name of Lemma('batch.n.02.mess')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.mickle')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.mint')> 1\n",
      "<bound method Lemma.name of Lemma('batch.n.02.mountain')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.muckle')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.passel')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.peck')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.pile')> 3\n",
      "<bound method Lemma.name of Lemma('batch.n.02.plenty')> 2\n",
      "<bound method Lemma.name of Lemma('batch.n.02.pot')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.quite_a_little')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.raft')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.sight')> 1\n",
      "<bound method Lemma.name of Lemma('batch.n.02.slew')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.spate')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.stack')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.tidy_sum')> 0\n",
      "<bound method Lemma.name of Lemma('batch.n.02.wad')> 0\n",
      "<bound method Lemma.name of Lemma('push-down_list.n.01.push-down_list')> 0\n",
      "<bound method Lemma.name of Lemma('push-down_list.n.01.push-down_stack')> 0\n",
      "<bound method Lemma.name of Lemma('push-down_list.n.01.stack')> 0\n",
      "<bound method Lemma.name of Lemma('smokestack.n.01.smokestack')> 0\n",
      "<bound method Lemma.name of Lemma('smokestack.n.01.stack')> 0\n",
      "<bound method Lemma.name of Lemma('push-down_storage.n.01.push-down_storage')> 0\n",
      "<bound method Lemma.name of Lemma('push-down_storage.n.01.push-down_store')> 0\n",
      "<bound method Lemma.name of Lemma('push-down_storage.n.01.stack')> 0\n",
      "<bound method Lemma.name of Lemma('stack.v.01.stack')> 2\n",
      "<bound method Lemma.name of Lemma('stack.v.02.stack')> 0\n",
      "<bound method Lemma.name of Lemma('stack.v.02.pile')> 8\n",
      "<bound method Lemma.name of Lemma('stack.v.02.heap')> 1\n",
      "<bound method Lemma.name of Lemma('stack.v.03.stack')> 0\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "syns = wordnet.synsets('stack')\n",
    "for s in syns:\n",
    "    for l in s.lemmas():\n",
    "        print(str(l.name) + \" \" + str(l.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtualenv",
   "language": "python",
   "name": "virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
