{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'originated', 'from', 'the', 'idea', 'that', 'there', 'are', 'readers', 'who', 'prefer', 'learning', 'new', 'skills', 'from', 'the', 'comforts', 'of', 'their', 'drawing', 'rooms', '.', 'Lilies', 'are', 'pretty', '.']\n",
      "\n",
      "\n",
      "Actual: It  Stem: It\n",
      "Actual: originated  Stem: origin\n",
      "Actual: from  Stem: from\n",
      "Actual: the  Stem: the\n",
      "Actual: idea  Stem: idea\n",
      "Actual: that  Stem: that\n",
      "Actual: there  Stem: there\n",
      "Actual: are  Stem: are\n",
      "Actual: readers  Stem: reader\n",
      "Actual: who  Stem: who\n",
      "Actual: prefer  Stem: prefer\n",
      "Actual: learning  Stem: learn\n",
      "Actual: new  Stem: new\n",
      "Actual: skills  Stem: skill\n",
      "Actual: from  Stem: from\n",
      "Actual: the  Stem: the\n",
      "Actual: comforts  Stem: comfort\n",
      "Actual: of  Stem: of\n",
      "Actual: their  Stem: their\n",
      "Actual: drawing  Stem: draw\n",
      "Actual: rooms  Stem: room\n",
      "Actual: .  Stem: .\n",
      "Actual: Lilies  Stem: lili\n",
      "Actual: are  Stem: are\n",
      "Actual: pretty  Stem: pretti\n",
      "Actual: .  Stem: .\n",
      "\n",
      "\n",
      "After porter stemming we get: It origin from the idea that there are reader who prefer learn new skill from the comfort of their draw room . lili are pretti .\n"
     ]
    }
   ],
   "source": [
    "document_1 = []\n",
    "word_data = \"It originated from the idea that there are readers who prefer learning new skills from the comforts of their drawing rooms. Lilies are pretty.\"\n",
    "\n",
    "nltk_tokens = nltk.word_tokenize(word_data)\n",
    "\n",
    "print(nltk_tokens)\n",
    "print('\\n')\n",
    "\n",
    "for w in nltk_tokens:\n",
    "    print(\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))\n",
    "    document_1.append(porter_stemmer.stem(w))\n",
    "\n",
    "print('\\n')\n",
    "port = ' '.join(word for word in document_1)\n",
    "print(\"After porter stemming we get:\",port)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: flies  Stem: fli\n",
      "Actual: dies  Stem: die\n",
      "Actual: mules  Stem: mule\n",
      "Actual: denied  Stem: deni\n",
      "Actual: died  Stem: die\n",
      "Actual: agreed  Stem: agre\n",
      "Actual: owned  Stem: own\n",
      "Actual: humbled  Stem: humbl\n",
      "Actual: sized  Stem: size\n",
      "Actual: meeting  Stem: meet\n",
      "Actual: stating  Stem: state\n",
      "Actual: siezing  Stem: siez\n",
      "Actual: itemization  Stem: item\n",
      "Actual: sensational  Stem: sensat\n",
      "Actual: traditional  Stem: tradit\n",
      "Actual: reference  Stem: refer\n",
      "Actual: colonizer  Stem: colon\n",
      "Actual: plotted  Stem: plot\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "document_2 = ['flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', 'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', 'traditional', 'reference', 'colonizer','plotted']\n",
    "for w in document_2:\n",
    "    print(\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))\n",
    "    document_1.append(porter_stemmer.stem(w))\n",
    "\n",
    "print('\\n')\n",
    "port = ' '.join(word for word in document_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: flies  Stem: fli\n",
      "Actual: dies  Stem: die\n",
      "Actual: mules  Stem: mule\n",
      "Actual: denied  Stem: deni\n",
      "Actual: died  Stem: die\n",
      "Actual: agreed  Stem: agre\n",
      "Actual: owned  Stem: own\n",
      "Actual: humbled  Stem: humbl\n",
      "Actual: sized  Stem: size\n",
      "Actual: meeting  Stem: meet\n",
      "Actual: stating  Stem: state\n",
      "Actual: siezing  Stem: siez\n",
      "Actual: itemization  Stem: item\n",
      "Actual: sensational  Stem: sensat\n",
      "Actual: traditional  Stem: tradit\n",
      "Actual: reference  Stem: refer\n",
      "Actual: colonizer  Stem: colon\n",
      "Actual: plotted  Stem: plot\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_2 = ['flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', 'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', 'traditional', 'reference', 'colonizer','plotted']\n",
    "\n",
    "english_stemmer = SnowballStemmer(\"english\")\n",
    "for w in document_2:\n",
    "    print(\"Actual: %s  Stem: %s\"  % (w,english_stemmer.stem(w)))\n",
    "    document_1.append(english_stemmer.stem(w))\n",
    "\n",
    "print('\\n')\n",
    "port = ' '.join(word for word in document_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
